{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15741d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "\n",
    "# nlp libraries\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "import string\n",
    "import re\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim import corpora\n",
    "import pyLDAvis\n",
    "import pandas as pd\n",
    "\n",
    "# visualization libraries\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94097f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter matplotlib backend magic\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1efee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reading in the dataset according to year input\n",
    "\n",
    "def read_textfile(year):\n",
    "    file = pd.read_csv(f'fem_df{year}.csv')\n",
    "    return file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251eff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.0.0/de_core_news_sm-3.0.0-py3-none-any.whl (19.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.3/19.3 MB 16.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from de-core-news-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.27.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: pathy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (4.60.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.20.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (56.2.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pathy->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90ae170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions performing nlp - analysis\n",
    "\n",
    "# loading german corpus from spacy library\n",
    "global nlp\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328f2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cleaning and splitting input texts for further processing\n",
    "\n",
    "def file_io(filename):\n",
    "    f_io = filename.split('.')\n",
    "    f_c = [re.sub('\\\\n', '', f) for f in f_io]\n",
    "    return f_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5317cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs pos-tagging on sentence and returns list with pos-tags\n",
    "\n",
    "def pos_tagger(sent):\n",
    "    doc = nlp(sent)\n",
    "    pos_tags = [token.tag_ for token in doc]\n",
    "    return pos_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6405324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that searches string for named entities and returns list of entities\n",
    "\n",
    "def recog_ne(sent):\n",
    "    doc = nlp(sent)\n",
    "    named_ents = [ent.label_ for ent in doc.ents]\n",
    "    return named_ents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760e99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs sentiment analysis on a given string and returns polarity\n",
    "\n",
    "def sent_analysis(sent):\n",
    "    blob = TextBlob(sent)\n",
    "    return blob.sentiment[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746fbe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that creates a wordcloud derived from topic modeling\n",
    "\n",
    "def wc_from_tm(input_string, num_topics=1):\n",
    "    # Process the input string using the German language model\n",
    "    doc = nlp(input_string)\n",
    "\n",
    "    # Tokenize the input string, removing stop words and punctuation\n",
    "    tokens = [token.lemma_ for token in doc\n",
    "              if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    # Create a dictionary from the tokenized input\n",
    "    dictionary = corpora.Dictionary([tokens])\n",
    "\n",
    "    # Create a bag of words representation of the input\n",
    "    bow = [dictionary.doc2bow(tokens)]\n",
    "\n",
    "    # Train the LDA model on the input\n",
    "    lda_model = LdaModel(bow, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "    topic_distribution = lda_model[bow]\n",
    "    # Create a word cloud for each topic\n",
    "    for topic_id, topic_prob in topic_distribution[0]:\n",
    "        topic = lda_model.show_topic(topic_id)\n",
    "        topic_words = \" \".join([word for word, prob in topic])\n",
    "        wordcloud = WordCloud(background_color='white',\n",
    "                              width=400,\n",
    "                              height=200,\n",
    "                              max_words=200,\n",
    "                              max_font_size=50,\n",
    "                              min_font_size=12).generate(topic_words)\n",
    "        \n",
    "    return wordcloud.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0e1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function for creating an ordered, counted dictionary\n",
    "\n",
    "def count_dict(obj_to_count_from):\n",
    "    c = Counter(obj_to_count_from)\n",
    "    sort_c = sorted(c.items(), key=lambda x:x[1], reverse=True)\n",
    "    sort_dict_c = {obj[0]: obj[1] for obj in sort_c}\n",
    "    return sort_dict_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aea3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for visualizing the data\n",
    "\n",
    "def visualize_data(text_num=0, year=2019):\n",
    "    \n",
    "    if text_num > len(read_textfile(year)):\n",
    "        return\n",
    "    \n",
    "    inp_string = read_textfile(year)\n",
    "    \n",
    "    text_to_vis = inp_string[f'articles_{year}'][text_num]\n",
    "    \n",
    "    # prepare necessary data\n",
    "    text_to_analyze = file_io(text_to_vis)\n",
    "\n",
    "    pos_tag_count = count_dict(pos_tagger(text_to_vis))\n",
    "\n",
    "    # count the named entities\n",
    "\n",
    "    ne = []\n",
    "\n",
    "    for sen in text_to_analyze:\n",
    "        ne += recog_ne(sen)\n",
    "\n",
    "    counted_na_ent = count_dict(ne)\n",
    "\n",
    "\n",
    "    # sent_analysis for whole article\n",
    "\n",
    "    sent_an = [sent_analysis(sent) for sent in text_to_analyze]\n",
    "\n",
    "    # make dataframes for visualizations\n",
    "\n",
    "    make_df = {'Pos Tags':pos_tag_count.keys(),\n",
    "               'Count': pos_tag_count.values()}\n",
    "\n",
    "    make_df_na = {'Named Entities':counted_na_ent.keys(),\n",
    "                  'Count': counted_na_ent.values()}\n",
    "\n",
    "    df_make_sa = {'Sentence No.': list(range(len(sent_an))),\n",
    "                  'Sentiment Polarity': sent_an}\n",
    "\n",
    "    df_sa = pd.DataFrame(df_make_sa)\n",
    "    df_na = pd.DataFrame(make_df_na)\n",
    "    df_pt = pd.DataFrame(make_df)\n",
    "    wc_array = wc_from_tm(text_to_vis)\n",
    "\n",
    "\n",
    "    # making the subplots\n",
    "    fig_sb = sp.make_subplots(rows=2,\n",
    "                              cols=2,\n",
    "                              subplot_titles=(\"Pos Tags\",\n",
    "                                              \"Named Entites\",\n",
    "                                              \"Sentiment Analysis\",\n",
    "                                              \"WordCloud from Topic Modeling\"),\n",
    "                              specs=[[{'type':'bar'}, {'type':'domain'}],\n",
    "                                    [{'type':'xy'}, {}]])\n",
    "\n",
    "\n",
    "        # first one = barplot pos_tags\n",
    "    fig_pt = go.Bar(x = df_pt['Pos Tags'],\n",
    "             y = df_pt['Count'],\n",
    "             marker_color=list(range(len(df_pt['Pos Tags'])))[::-1])\n",
    "\n",
    "\n",
    "        # second one = pieplot named entities\n",
    "    fig_na = go.Pie(labels=df_na['Named Entities'],\n",
    "                    values=df_na['Count'])\n",
    "\n",
    "\n",
    "    # third one = line plot sentiment analysis\n",
    "\n",
    "    fig_sa = go.Scatter(x=df_sa['Sentence No.'],\n",
    "                        y = df_sa['Sentiment Polarity'])\n",
    "\n",
    "\n",
    "    fig_wc = go.Image(z=wc_array, hoverinfo='none')\n",
    "\n",
    "\n",
    "        # adding to main plot\n",
    "\n",
    "    fig_sb.add_trace(fig_pt, row=1, col=1)\n",
    "    fig_sb.add_trace(fig_na, row=1, col=2)\n",
    "    fig_sb.add_trace(fig_sa, row=2, col=1)\n",
    "    fig_sb.add_trace(fig_wc, row=2, col=2)\n",
    "\n",
    "    # styling plot\n",
    "    fig_sb.update_xaxes(tickfont_size=10,  row=1, col=1)\n",
    "    fig_sb.update_xaxes(visible=False,  row=2, col=1)\n",
    "    fig_sb.update_xaxes(visible=False,  row=2, col=1)\n",
    "    fig_sb.update_xaxes(visible=False,  row=2, col=2)\n",
    "\n",
    "    fig_sb.update_yaxes(range=[-1, 1], row=2, col=1)\n",
    "    fig_sb.update_yaxes(visible=False,  row=2, col=2)\n",
    "    \n",
    "    fig_sb.update_annotations(yshift=12, \n",
    "                              font=dict(family='Courier New, monospace', \n",
    "                                        size=14, color='Black'))\n",
    "\n",
    "\n",
    "    fig_sb.update_layout(\n",
    "        width = 1350,\n",
    "        height = 600,\n",
    "        title='NLP Dashboard for Media Coverage of Femicides in Austria',\n",
    "        title_font=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='Black'\n",
    "            ),\n",
    "        showlegend=False\n",
    "        )\n",
    "\n",
    "    return fig_sb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82342217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating widgets\n",
    "\n",
    "\n",
    "text_select = widgets.BoundedIntText(\n",
    "                                    value=0,\n",
    "                                    min=0,\n",
    "                                    max=50,\n",
    "                                    step=1,\n",
    "                                    description='Article No.',\n",
    "                                    disabled=False)\n",
    "\n",
    "\n",
    "year_select = widgets.BoundedIntText(\n",
    "                                     value=2019,\n",
    "                                     min=2019,\n",
    "                                     max=2022,\n",
    "                                     step=1,\n",
    "                                     description='Year:',\n",
    "                                     disabled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74f9143",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center; font-family:Courier New, monospace; font-weight:bold;\">F.E.M.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd84ceeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f142eda705421a988883e9f6ce1734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=0, description='Article No.', max=50), BoundedIntText(value=2019, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int_act = widgets.interact(visualize_data, text_num=text_select, year=year_select)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
